{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cff4b2f-28d9-4175-91ff-76ec22ab3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "730497e9-7fe4-4d75-8645-292aff1d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2, os, shutil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7b70561-9a2b-440b-b182-3787f5c6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOX_COLOR = (255, 0, 0) # Red\n",
    "# TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "# def visualize_bbox(img, bbox, class_name, pic_w, pic_h, color=BOX_COLOR, thickness=2):\n",
    "#     dataType = \"yolo\"\n",
    "\n",
    "#     \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "\n",
    "#     if dataType == 'coco':\n",
    "#         x_min, y_min, w, h = bbox # 정규화 된 0~1 사이의 값\n",
    "#         x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "#     elif dataType == \"yolo\":\n",
    "#         x_center, y_center, w, h = bbox\n",
    "#         # 픽셀 좌표로 변환 이미지의 width와 height값\n",
    "#         x_min = int(float(x_center - w/2) * pic_w)\n",
    "#         x_max = int(float(x_center + w/2) * pic_w)\n",
    "#         y_min = int(float(y_center - h/2) * pic_h)\n",
    "#         y_max = int(float(y_center + h/2) * pic_h)\n",
    "#     print(w, h)\n",
    "#     print(x_min, y_min, y_min, y_max)\n",
    "#     cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "#     ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "#     cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "#     cv2.putText(\n",
    "#         img,\n",
    "#         text=class_name,\n",
    "#         org=(x_min, y_min - int(0.3 * text_height)),\n",
    "#         fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#         fontScale=0.35,\n",
    "#         color=TEXT_COLOR,\n",
    "#         lineType=cv2.LINE_AA,\n",
    "#     )\n",
    "#     return img\n",
    "\n",
    "\n",
    "# def visualize(image, bboxes, category_ids, category_id_to_name, img_shape):\n",
    "#     img = image.copy()\n",
    "#     h,w = img_shape[0:2]\n",
    "#     print(bboxes)\n",
    "#     print(category_ids)\n",
    "#     for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         class_name = category_id_to_name[category_id]\n",
    "#         img = visualize_bbox(img, bbox, class_name, w, h)\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c47a46d-64ec-4b53-a196-a1c3c6599013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_label_txt(txtFile):\n",
    "#     category_ids = []\n",
    "#     bboxes = []\n",
    "\n",
    "#     f=open(txtFile,'r')\n",
    "\n",
    "#     while True:\n",
    "#         line = f.readline()\n",
    "#         if not line: break\n",
    "#         ids, xc, yc, w, h= line.split(' ')\n",
    "#         category_ids.append(int(ids))\n",
    "#         bboxes.append([float(xc),float(yc),float(w),float(h)])\n",
    "#         #print(line)\n",
    "#     f.close()\n",
    "#     return category_ids, bboxes\n",
    "\n",
    "# def write_label_txt(txtFile, category_ids, bboxes):\n",
    "#     f=open(txtFile,'w')\n",
    "\n",
    "#     for i, ids in enumerate(category_ids):\n",
    "#         xc,yc,w,h = bboxes[i]\n",
    "#         f.write(\"{} {} {} {} {}\\n\".format(int(ids),xc,yc,w,h))\n",
    "#         #print(\"{} {}\".format(int(ids), bboxes[i]))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6687c3c4-df87-419b-bef5-96ef0b2d223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtFile = 'sepImgLabSimpson/bart/bart_labels/pic_0000.txt'\n",
    "# imagePath = 'sepImgLabSimpson/bart/bart_images/pic_0000.jpg'\n",
    "# image = cv2.imread(imagePath)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# category_ids, bboxes = read_label_txt(txtFile)\n",
    "# category_id_to_name = {0: 'bart', 1: 'homer', 2: 'lisa', 3: 'maggie', 4: 'marge'}\n",
    "# visualize(image, bboxes, category_ids, category_id_to_name, image.shape[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb5cb172-6c73-409f-882e-6fa98e90aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatio = 0.7\n",
    "validRatio = 0.15\n",
    "testRatio = 1 - trainRatio - validRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4a929d9-2d0e-4873-8aad-8fc11785b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 938] valid [939, 1139] test [1140, 1341]\n",
      "train [0, 1129] valid [1130, 1371] test [1372, 1614]\n",
      "train [0, 946] valid [947, 1148] test [1149, 1352]\n",
      "train [0, 88] valid [89, 107] test [108, 127]\n",
      "데이터셋 분할 및 복사가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# 데이터셋 디렉토리 경로 설정 (데이터셋이 저장된 경로로 수정하세요)\n",
    "dataset_dir = os.path.join(os.getcwd(), 'sepImgLabSimpson')\n",
    "\n",
    "# 새로운 train, valid, test 디렉토리 생성 경로\n",
    "base_dir = os.path.join(os.getcwd(), 'sepImgLabSimpson_tvt')\n",
    "\n",
    "# 클래스 목록\n",
    "classes = ['bart', 'homer', 'lisa', 'maggie'] #marge\n",
    "fileTypes = ['images','labels']\n",
    "\n",
    "# 폴더 경로 생성\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# 폴더 생성 함수\n",
    "def create_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# train, valid, test 폴더 및 각각의 클래스 폴더 생성\n",
    "# 각각의 클래스 폴더 및 이미지와 레이블 폴더 생성 \n",
    "for fileType in fileTypes:\n",
    "    create_dir(os.path.join(train_dir, fileType))\n",
    "    create_dir(os.path.join(valid_dir, fileType))\n",
    "    create_dir(os.path.join(test_dir, fileType))\n",
    "\n",
    "def checkEqual(filesPath, label):\n",
    "    images_path = os.path.join(filesPath, str(label + '_images'))\n",
    "    labels_path = os.path.join(filesPath, str(label + '_labels'))\n",
    "    imageFiles = os.listdir(images_path)\n",
    "    labelFiles = os.listdir(labels_path)\n",
    "    if len(imageFiles) != len(labelFiles):\n",
    "        print(f'{label} imageFiles {len(imageFiles)} and labelFiles {len(labelFiles)} not equal')\n",
    "        for count in range(len(labelFiles)):\n",
    "            print(f'{count} imageFiles {imageFiles[count]} labelFiles {labelFiles[count]}')\n",
    "        img_mismatch_list = [True] * len(imageFiles)\n",
    "        label_mismatch_list = [True] * len(labelFiles)\n",
    "\n",
    "        for count, image in enumerate(imageFiles):\n",
    "            for label in labelFiles:\n",
    "                if os.path.splitext(image)[0] == os.path.splitext(label)[0]:\n",
    "                    img_mismatch_list[count] = False\n",
    "                    break\n",
    "        for count, label in enumerate(labelFiles):\n",
    "            for image in imageFiles:\n",
    "                if os.path.splitext(label)[0] == os.path.splitext(image)[0]:\n",
    "                    label_mismatch_list[count] = False\n",
    "                    break\n",
    "                    \n",
    "        for count in range(len(imageFiles)):\n",
    "            if img_mismatch_list[count]: \n",
    "                print(f'no label for the following images: {imageFiles[count]}')\n",
    "        for count in range(len(labelFiles)):\n",
    "            if label_mismatch_list[count]: \n",
    "                print(f'no image for the following labels: {labelFiles[count]}')\n",
    "        return False\n",
    "    \n",
    "    return True \n",
    "\n",
    "# 이미지 복사 함수\n",
    "def copy_images_and_labels(start_idx, end_idx, src_dir, dst_dir, label):\n",
    "    src_img_dir = os.path.join(src_dir, str(label + '_images'))\n",
    "    src_label_dir = os.path.join(src_dir, str(label + '_labels'))\n",
    "    srcImages = os.listdir( src_img_dir )\n",
    "    srcLabels = os.listdir( src_label_dir )\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        image_name = f'{label}.{i}.jpg'\n",
    "        label_name = f'{label}.{i}.txt'\n",
    "        src_imagePath = os.path.join(src_img_dir, srcImages[i])\n",
    "        src_labelPath = os.path.join(src_label_dir, srcLabels[i])\n",
    "        dst_imagePath = os.path.join(dst_dir, 'images', image_name)\n",
    "        dst_labelPath = os.path.join(dst_dir, 'labels', label_name)\n",
    "        \n",
    "        if os.path.exists(src_imagePath):\n",
    "            shutil.copy(src_imagePath, dst_imagePath)\n",
    "        if os.path.exists(src_labelPath):\n",
    "            shutil.copy(src_labelPath, dst_labelPath)\n",
    "\n",
    "# 클래스 별로 train, valid, test 데이터셋 구성\n",
    "for cls in classes:\n",
    "    #retrieve image count\n",
    "    filesPath = os.path.join(os.getcwd(), 'sepImgLabSimpson', cls)\n",
    "\n",
    "    if checkEqual(filesPath, cls):\n",
    "    \n",
    "        files = os.listdir( os.path.join(filesPath, str(cls + '_images')))\n",
    "        \n",
    "        train_num = int(trainRatio * len(files))\n",
    "        valid_num = int(validRatio * len(files))\n",
    "        test_num  = len(files) - train_num - valid_num \n",
    "    \n",
    "        train_range = [0, train_num-1]\n",
    "        valid_range = [train_num, train_num + valid_num -1]\n",
    "        test_range  = [train_num + valid_num, train_num + valid_num + test_num-1]\n",
    "        print(f'train {train_range} valid {valid_range} test {test_range}')\n",
    "    \n",
    "        #copy images and label\n",
    "        copy_images_and_labels(train_range[0], train_range[1], os.path.join(dataset_dir, cls), os.path.join(train_dir), cls)\n",
    "    \n",
    "        # valid dataset 구성 (1000~1249)\n",
    "        copy_images_and_labels(valid_range[0], valid_range[1], os.path.join(dataset_dir,cls), os.path.join(valid_dir), cls)\n",
    "    \n",
    "        # test dataset 구성 (1250~1499)\n",
    "        copy_images_and_labels(test_range[0], test_range[1], os.path.join(dataset_dir,cls), os.path.join(test_dir), cls)\n",
    "\n",
    "print(\"데이터셋 분할 및 복사가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b12d6-99c9-4264-b850-512d57d52e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.14 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,620 parameters, 2,590,604 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SBA\\simpson\\sepImgLabSimpson_tvt\\train\\labels...:   0%|          | 0/3105 [00:00<?, ?it/s]\u001b[0mException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001A6FB12F250>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SBA\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1477, in __del__\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SBA\\simpson\\sepImgLabSimpson_tvt\\train\\labels... 3 images, 0 backgrounds, 0 corrupt:   0%|    \u001b[0m    self._shutdown_workers()\n",
      "  File \"C:\\Users\\SBA\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1435, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SBA\\simpson\\sepImgLabSimpson_tvt\\train\\labels... 3105 images, 3 backgrounds, 0 corrupt: 100%|█\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\SBA\\simpson\\sepImgLabSimpson_tvt\\train\\labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "results = model.train(data='data.yaml', epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430495b-1372-44fe-939b-96d1e2e69c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
