{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cff4b2f-28d9-4175-91ff-76ec22ab3f6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\cuda\\memory.py:170\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 170\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "730497e9-7fe4-4d75-8645-292aff1d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2, os, shutil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b70561-9a2b-440b-b182-3787f5c6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOX_COLOR = (255, 0, 0) # Red\n",
    "# TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "# def visualize_bbox(img, bbox, class_name, pic_w, pic_h, color=BOX_COLOR, thickness=2):\n",
    "#     dataType = \"yolo\"\n",
    "\n",
    "#     \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "\n",
    "#     if dataType == 'coco':\n",
    "#         x_min, y_min, w, h = bbox # 정규화 된 0~1 사이의 값\n",
    "#         x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "#     elif dataType == \"yolo\":\n",
    "#         x_center, y_center, w, h = bbox\n",
    "#         # 픽셀 좌표로 변환 이미지의 width와 height값\n",
    "#         x_min = int(float(x_center - w/2) * pic_w)\n",
    "#         x_max = int(float(x_center + w/2) * pic_w)\n",
    "#         y_min = int(float(y_center - h/2) * pic_h)\n",
    "#         y_max = int(float(y_center + h/2) * pic_h)\n",
    "#     print(w, h)\n",
    "#     print(x_min, y_min, y_min, y_max)\n",
    "#     cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "#     ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "#     cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "#     cv2.putText(\n",
    "#         img,\n",
    "#         text=class_name,\n",
    "#         org=(x_min, y_min - int(0.3 * text_height)),\n",
    "#         fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#         fontScale=0.35,\n",
    "#         color=TEXT_COLOR,\n",
    "#         lineType=cv2.LINE_AA,\n",
    "#     )\n",
    "#     return img\n",
    "\n",
    "\n",
    "# def visualize(image, bboxes, category_ids, category_id_to_name, img_shape):\n",
    "#     img = image.copy()\n",
    "#     h,w = img_shape[0:2]\n",
    "#     print(bboxes)\n",
    "#     print(category_ids)\n",
    "#     for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         class_name = category_id_to_name[category_id]\n",
    "#         img = visualize_bbox(img, bbox, class_name, w, h)\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c47a46d-64ec-4b53-a196-a1c3c6599013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_label_txt(txtFile):\n",
    "#     category_ids = []\n",
    "#     bboxes = []\n",
    "\n",
    "#     f=open(txtFile,'r')\n",
    "\n",
    "#     while True:\n",
    "#         line = f.readline()\n",
    "#         if not line: break\n",
    "#         ids, xc, yc, w, h= line.split(' ')\n",
    "#         category_ids.append(int(ids))\n",
    "#         bboxes.append([float(xc),float(yc),float(w),float(h)])\n",
    "#         #print(line)\n",
    "#     f.close()\n",
    "#     return category_ids, bboxes\n",
    "\n",
    "# def write_label_txt(txtFile, category_ids, bboxes):\n",
    "#     f=open(txtFile,'w')\n",
    "\n",
    "#     for i, ids in enumerate(category_ids):\n",
    "#         xc,yc,w,h = bboxes[i]\n",
    "#         f.write(\"{} {} {} {} {}\\n\".format(int(ids),xc,yc,w,h))\n",
    "#         #print(\"{} {}\".format(int(ids), bboxes[i]))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6687c3c4-df87-419b-bef5-96ef0b2d223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtFile = 'sepImgLabSimpson/bart/bart_labels/pic_0000.txt'\n",
    "# imagePath = 'sepImgLabSimpson/bart/bart_images/pic_0000.jpg'\n",
    "# image = cv2.imread(imagePath)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# category_ids, bboxes = read_label_txt(txtFile)\n",
    "# category_id_to_name = {0: 'bart', 1: 'homer', 2: 'lisa', 3: 'maggie', 4: 'marge'}\n",
    "# visualize(image, bboxes, category_ids, category_id_to_name, image.shape[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5cb172-6c73-409f-882e-6fa98e90aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatio = 0.7\n",
    "validRatio = 0.15\n",
    "testRatio = 1 - trainRatio - validRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a929d9-2d0e-4873-8aad-8fc11785b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 938] valid [939, 1139] test [1140, 1341]\n",
      "train [0, 1129] valid [1130, 1371] test [1372, 1614]\n",
      "train [0, 946] valid [947, 1148] test [1149, 1352]\n",
      "train [0, 88] valid [89, 107] test [108, 127]\n",
      "데이터셋 분할 및 복사가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "# 데이터셋 디렉토리 경로 설정 (데이터셋이 저장된 경로로 수정하세요)\n",
    "dataset_dir = os.path.join(os.getcwd(), 'sepImgLabSimpson')\n",
    "\n",
    "# 새로운 train, valid, test 디렉토리 생성 경로\n",
    "base_dir = os.path.join(os.getcwd(), 'sepImgLabSimpson_tvt')\n",
    "\n",
    "# 클래스 목록\n",
    "classes = ['bart', 'homer', 'lisa', 'maggie'] #marge\n",
    "fileTypes = ['images','labels']\n",
    "\n",
    "# 폴더 경로 생성\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# 폴더 생성 함수\n",
    "def create_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# train, valid, test 폴더 및 각각의 클래스 폴더 생성\n",
    "# 각각의 클래스 폴더 및 이미지와 레이블 폴더 생성 \n",
    "for fileType in fileTypes:\n",
    "    create_dir(os.path.join(train_dir, fileType))\n",
    "    create_dir(os.path.join(valid_dir, fileType))\n",
    "    create_dir(os.path.join(test_dir, fileType))\n",
    "\n",
    "def checkEqual(filesPath, label):\n",
    "    images_path = os.path.join(filesPath, str(label + '_images'))\n",
    "    labels_path = os.path.join(filesPath, str(label + '_labels'))\n",
    "    imageFiles = os.listdir(images_path)\n",
    "    labelFiles = os.listdir(labels_path)\n",
    "    if len(imageFiles) != len(labelFiles):\n",
    "        print(f'{label} imageFiles {len(imageFiles)} and labelFiles {len(labelFiles)} not equal')\n",
    "        for count in range(len(labelFiles)):\n",
    "            print(f'{count} imageFiles {imageFiles[count]} labelFiles {labelFiles[count]}')\n",
    "        img_mismatch_list = [True] * len(imageFiles)\n",
    "        label_mismatch_list = [True] * len(labelFiles)\n",
    "\n",
    "        for count, image in enumerate(imageFiles):\n",
    "            for label in labelFiles:\n",
    "                if os.path.splitext(image)[0] == os.path.splitext(label)[0]:\n",
    "                    img_mismatch_list[count] = False\n",
    "                    break\n",
    "        for count, label in enumerate(labelFiles):\n",
    "            for image in imageFiles:\n",
    "                if os.path.splitext(label)[0] == os.path.splitext(image)[0]:\n",
    "                    label_mismatch_list[count] = False\n",
    "                    break\n",
    "                    \n",
    "        for count in range(len(imageFiles)):\n",
    "            if img_mismatch_list[count]: \n",
    "                print(f'no label for the following images: {imageFiles[count]}')\n",
    "        for count in range(len(labelFiles)):\n",
    "            if label_mismatch_list[count]: \n",
    "                print(f'no image for the following labels: {labelFiles[count]}')\n",
    "        return False\n",
    "    \n",
    "    return True \n",
    "\n",
    "# def matchAndShuffle(filesPath):\n",
    "#     img_dir = os.path.join(src_dir, str(label + '_images'))\n",
    "#     label_dir = os.path.join(src_dir, str(label + '_labels'))\n",
    "#     imageFiles = os.listdir( src_img_dir )\n",
    "#     labelFiles = os.listdir( src_label_dir )\n",
    "#     imageFiles = random.sample(imageFiles, len(imageFiles))\n",
    "#     imageToLabel = dict.fromkeys(imageFiles)\n",
    "#     for image in imageFiles:\n",
    "#         for label in labelFiles:\n",
    "#             if os.path.splitext(image) == os.path.splitext(label):\n",
    "#                 imageToLabel[image] = label\n",
    "#     print(imageToLabel)\n",
    "    \n",
    "#     return imageToLabel\n",
    "\n",
    "# # 이미지 복사 함수\n",
    "# def copy_images_and_labels(start_idx, end_idx, imageLabelDict, dst_dir, label):\n",
    "#     for i in range(start_idx, end_idx + 1):\n",
    "#         image_name = f'{label}.{i}.jpg'\n",
    "#         label_name = f'{label}.{i}.txt'\n",
    "#         src_imagePath = imageLabelDict[]\n",
    "#         src_labelPath = os.path.join(src_label_dir, srcLabels[i])\n",
    "#         dst_imagePath = os.path.join(dst_dir, 'images', image_name)\n",
    "#         dst_labelPath = os.path.join(dst_dir, 'labels', label_name)\n",
    "        \n",
    "#         if os.path.exists(src_imagePath):\n",
    "#             shutil.copy(src_imagePath, dst_imagePath)\n",
    "#         if os.path.exists(src_labelPath):\n",
    "#             shutil.copy(src_labelPath, dst_labelPath)\n",
    "\n",
    "# 이미지 복사 함수\n",
    "def copy_images_and_labels(start_idx, end_idx, src_dir, dst_dir, label):\n",
    "    src_img_dir = os.path.join(src_dir, str(label + '_images'))\n",
    "    src_label_dir = os.path.join(src_dir, str(label + '_labels'))\n",
    "    srcImages = os.listdir( src_img_dir )\n",
    "    srcLabels = os.listdir( src_label_dir )\n",
    "    # print(f'srcImages1: {srcImages}')\n",
    "    # print(f'srcLabels1: {srcLabels}')\n",
    "    srcImages.sort()\n",
    "    srcLabels.sort()\n",
    "    # print(f'srcImages2: {srcImages}')\n",
    "    # print(f'srcLabels2: {srcLabels}')\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        image_name = f'{label}.{i}.jpg'\n",
    "        label_name = f'{label}.{i}.txt'\n",
    "        src_imagePath = os.path.join(src_img_dir, srcImages[i])\n",
    "        src_labelPath = os.path.join(src_label_dir, srcLabels[i])\n",
    "        dst_imagePath = os.path.join(dst_dir, 'images', image_name)\n",
    "        dst_labelPath = os.path.join(dst_dir, 'labels', label_name)\n",
    "        \n",
    "        if os.path.exists(src_imagePath):\n",
    "            shutil.copy(src_imagePath, dst_imagePath)\n",
    "        if os.path.exists(src_labelPath):\n",
    "            shutil.copy(src_labelPath, dst_labelPath)\n",
    "\n",
    "# 클래스 별로 train, valid, test 데이터셋 구성\n",
    "for cls in classes:\n",
    "    #retrieve image count\n",
    "    filesPath = os.path.join(os.getcwd(), 'sepImgLabSimpson', cls)\n",
    "\n",
    "    if checkEqual(filesPath, cls):\n",
    "    \n",
    "        files = os.listdir( os.path.join(filesPath, str(cls + '_images')))\n",
    "        \n",
    "        train_num = int(trainRatio * len(files))\n",
    "        valid_num = int(validRatio * len(files))\n",
    "        test_num  = len(files) - train_num - valid_num \n",
    "    \n",
    "        train_range = [0, train_num-1]\n",
    "        valid_range = [train_num, train_num + valid_num -1]\n",
    "        test_range  = [train_num + valid_num, train_num + valid_num + test_num-1]\n",
    "        print(f'train {train_range} valid {valid_range} test {test_range}')\n",
    "\n",
    "        # #create a dictionary matching label to image, then shuffle for equal distribution of samples in train, valid, and test folders each\n",
    "        # imageLabelDict = matchAndShuffle(filesPath)\n",
    "    \n",
    "        #copy images and label\n",
    "        copy_images_and_labels(train_range[0], train_range[1], os.path.join(dataset_dir, cls), os.path.join(train_dir), cls)\n",
    "    \n",
    "        # valid dataset 구성 (1000~1249)\n",
    "        copy_images_and_labels(valid_range[0], valid_range[1], os.path.join(dataset_dir,cls), os.path.join(valid_dir), cls)\n",
    "    \n",
    "        # test dataset 구성 (1250~1499)\n",
    "        copy_images_and_labels(test_range[0], test_range[1], os.path.join(dataset_dir,cls), os.path.join(test_dir), cls)\n",
    "\n",
    "print(\"데이터셋 분할 및 복사가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454b12d6-99c9-4264-b850-512d57d52e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m320\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\engine\\model.py:878\u001b[0m, in \u001b[0;36mModel._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03mApplies a function to model tensors that are not parameters or registered buffers.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;124;03m    >>> model = model._apply(lambda t: t.cuda())  # Move model to GPU\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_is_pytorch_model()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# reset predictor as device may have changed\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# was str(self.device) i.e. device(type='cuda', index=0) -> 'cuda:0'\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\nn\\tasks.py:258\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    Applies a function to all the tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m        (BaseModel): An updated BaseModel object.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Detect()\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Detect):  \u001b[38;5;66;03m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\yolov11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "results = model.train(data='data.yaml', epochs=50, imgsz=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430495b-1372-44fe-939b-96d1e2e69c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
